% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 01-Mar-2019 19:54:23
%
% This script assumes these variables are defined:
%
%   cancerInputs - input data.
%   cancerTargets - target data.
close all;

load cancer_dataset.mat

x = cancerInputs;
t = cancerTargets;

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainscg';  % Scaled conjugate gradient backpropagation.

epochs = [ 4 8 16 32 64 128 256];
nodes =[2 4 8 16 32 64 128 256];
result = zeros(length(epochs),length(nodes),2);

%%
for e_count = 1:length(epochs)
    for n_count = 1:length(nodes)
        % Create a Pattern Recognition Network
        % change the number of nodes [2 8 32]
        hiddenLayerSize = nodes(n_count);
        net = patternnet(hiddenLayerSize, trainFcn);
        % change the number of epochs [ 4 8 16 32 64]
        net.trainParam.epochs = epochs(e_count);

        % Choose Input and Output Pre/Post-Processing Functions
        % For a list of all processing functions type: help nnprocess
        net.input.processFcns = {'removeconstantrows','mapminmax'};

        % repeat at least 30 times for mesurement
        repeat = 50;

        % Setup Division of Data for Training, Validation, Testing
        % For a list of all data division functions type: help nndivision
        net.divideFcn = 'dividerand';  % Divide data randomly
        net.divideMode = 'sample';  % Divide up every sample

        % data division setup as required in EXP1
        net.divideParam.trainRatio = 50/100;
        net.divideParam.valRatio = 0/100;
        net.divideParam.testRatio = 50/100;

        % Choose a Performance Function
        % For a list of all performance functions type: help nnperformance
        net.performFcn = 'crossentropy';  % Cross-Entropy

        % Choose Plot Functions
        % For a list of all plot functions type: help nnplot
        net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
            'plotconfusion', 'plotroc'};

        percentErrors=zeros(repeat,1);
        for c=1:repeat
        % Train the Network
            [net,tr] = train(net,x,t,'useGPU','yes');

            % Test the Network
            y = net(x);
            e = gsubtract(t,y);
            performance = perform(net,t,y);
            tind = vec2ind(t);
            yind = vec2ind(y);
            percentErrors(c) = sum(tind ~= yind)/numel(tind);

            % Recalculate Training, Validation and Test Performance
            trainTargets = t .* tr.trainMask{1};
            %valTargets = t .* tr.valMask{1};
            testTargets = t .* tr.testMask{1};
            trainPerformance = perform(net,trainTargets,y);
            %valPerformance = perform(net,valTargets,y);
            testPerformance = perform(net,testTargets,y);

        end
        % View the Network
        %view(net)

        E_avg = mean(percentErrors);
        E_std = std(percentErrors);

        result(e_count,n_count,:) = [E_avg, E_std];
        fprintf ("finished %d/%d for nodes with %d/%d epochs\n", n_count,length(nodes),e_count,length(epochs));
    end
    plot(result(e_count,:,1),"-o");
    hold on;
    

end

%%
% after getting the result, now analize it
figure();
hold on;
%mesh(nodes,epochs,result(:,:,1))
subplot(2,2,1);
for e_count = 1:length(epochs)
    plot(1:length(nodes),result(e_count,:,1),"-o")
    hold on;
end
title("nodes vs error rate");
xlabel("number of nodes");
ylabel("error rate");
legend("epochs");

subplot(2,2,2);
for n_count = 1:length(nodes)
    plot(1:length(epochs),result(:,n_count,1),"-o")
    hold on;
end
title("epochs vs error rate");
xlabel("number of epochs");
ylabel("error rate");
legend("nodes");

subplot(2,2,3);
for e_count = 1:length(epochs)
    plot(1:length(nodes),result(e_count,:,2),"-o")
    hold on;
end
title("nodes vs std");
xlabel("number of nodes");
ylabel("std");
legend("epochs");

subplot(2,2,4);
for n_count = 1:length(nodes)
    plot(1:length(epochs),result(:,n_count,2),"-o")
    hold on;
end
title("epochs vs std");
xlabel("number of epochs");
ylabel("std");
legend("nodes");

min_avg = min(min(result(:,:,1)));
[min_epoch, min_node]=find(result==min_avg);
min_node = nodes(min_node)
min_epoch = epochs(min_epoch)


%%   
% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, ploterrhist(e)
%figure, plotconfusion(t,y)
%figure, plotroc(t,y)

% Deployment
% Change the (false) values to (true) to enable the following code blocks.
% See the help for each generation function for more information.
% if (false)
%     % Generate MATLAB function for neural network for application
%     % deployment in MATLAB scripts or with MATLAB Compiler and Builder
%     % tools, or simply to examine the calculations your trained neural
%     % network performs.
%     genFunction(net,'myNeuralNetworkFunction');
%     y = myNeuralNetworkFunction(x);
% end
% if (false)
%     % Generate a matrix-only MATLAB function for neural network code
%     % generation with MATLAB Coder tools.
%     genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
%     y = myNeuralNetworkFunction(x);
% end
% if (false)
%     % Generate a Simulink diagram for simulation or deployment with.
%     % Simulink Coder tools.
%     gensim(net);
% end
